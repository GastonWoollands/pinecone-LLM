{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pypdf cohere tiktoken langchain sentence_transformers openai pinecone-client -q\n",
    "# !pip install -U langchain-google-genai pillow\n",
    "\n",
    "# import streamlit as st\n",
    "import os\n",
    "from pathlib import Path\n",
    "# import numpy as np\n",
    "# import requests\n",
    "import pinecone\n",
    "from pprint import pprint\n",
    "\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "import google.generativeai as genai\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "os.chdir('C:/Users/Gwool/Documents/Python Scripts/LLM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chunks(doc_to_chunk):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=800,\n",
    "        chunk_overlap=100,\n",
    "        length_function=len\n",
    "        )\n",
    "    return text_splitter.split_documents(doc_to_chunk)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "\n",
    "def load_pdf(path):\n",
    "    loader = PyPDFLoader(path)\n",
    "    return loader.load()\n",
    "\n",
    "# -----------------------------------------------------\n",
    "\n",
    "def load_chunck_file(path):\n",
    "    doc = load_pdf(path)\n",
    "    return create_chunks(doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Pinecone Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n",
    "PINECONE_ENV = \"gcp-starter\"\n",
    "index_name = 'test-llm'\n",
    "dim = 768\n",
    "\n",
    "pinecone.init(api_key=PINECONE_API_KEY, environment=PINECONE_ENV)\n",
    "\n",
    "pinecone.create_index(index_name, dimension = dim, metric = \"cosine\")\n",
    "\n",
    "print(pinecone.describe_index(index_name))\n",
    "\n",
    "index = pinecone.Index(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load PDF File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N° Chunks: 371\n"
     ]
    }
   ],
   "source": [
    "file_path = './data/DNU-Milei-2023.pdf'\n",
    "\n",
    "chunks = load_chunck_file(file_path)\n",
    "print('N° Chunks:', len(chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name = model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load chunck PDF File into Pinecone Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pinecone.from_documents(chunks, embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversation with Gemini-Pro - Give context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "Por favor, responde a la pregunta con el mayor detalle posible en base al contexto proporcionado.\n",
    "Asegúrate de incluir todos los detalles relevantes. Si la respuesta no está disponible en el contexto proporcionado, por favor responde con \n",
    "\"La respuesta no está disponible en el contexto\". Evita proporcionar respuestas incorrectas.\n",
    "\\n\\n\n",
    "  Context:\\n {context}?\\n\n",
    "  Question: \\n{question}\\n\n",
    "\n",
    "  Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template = prompt_template, input_variables = [\"context\", \"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vstore = Pinecone.from_existing_index(index_name, embeddings)\n",
    "llm = ChatGoogleGenerativeAI(model = \"gemini-pro\", convert_system_message_to_human = True, temperature = 0.3)\n",
    "chain = load_qa_chain(llm, chain_type = \"stuff\", prompt = prompt) # map_reduce - stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_querying(question):\n",
    "    vstore = Pinecone.from_existing_index(index_name, embeddings)\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", convert_system_message_to_human=True, temperature=0.3)\n",
    "    chain = load_qa_chain(llm, chain_type=\"stuff\", prompt=prompt)  # map_reduce - stuff\n",
    "\n",
    "    docs = vstore.similarity_search(question, 3)\n",
    "\n",
    "    response = chain({\"input_documents\":docs, \"question\": question}, return_only_outputs=True)\n",
    "    response_text = response.get('output_text')\n",
    "\n",
    "    return pprint(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('- Se eliminan las figuras jurídicas de las Sociedades del Estado, reguladas '\n",
      " 'por la Ley N° 20.705, las Empresas del Estado previstas en la Ley N° 13.653 '\n",
      " 'y las Sociedades de Economía Mixta contempladas en el Decreto - Ley N° '\n",
      " '15.349/46.\\n'\n",
      " '- Se modifica el capítulo del Programa de Propiedad Participada de la Ley N° '\n",
      " '23.696, a los fines de facilitar el traspaso de las acciones de las empresas '\n",
      " 'actualmente estatales a sus empleados.\\n'\n",
      " '- Se incluyen cambios en la Ley N° 21.799 para adecuar al BANCO DE LA NACIÓN '\n",
      " 'ARGENTINA a su nueva configuración societaria.\\n'\n",
      " '- Se modifica el status jurídico de las empresas públicas, reconvirtiéndolas '\n",
      " 'en Sociedades Anónimas, acordes al régimen de la Ley General de Sociedades.')\n"
     ]
    }
   ],
   "source": [
    "data_querying('¿Que medidas se toman sobre las empresas del estado? Detalla la respuesta')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
